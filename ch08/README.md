Ch08

# 텍스트 처리용 데이터 준비
    - 압축 해제
    - 라벨 붙임
    - 경로에 정리
    - 데이터 프레임 섞음
    - csv파일로 저장

# BoW모델
1. CountVectorizer: 어휘 사전 만들기 -> 특성 백터 생성 (bow 행렬 생성)
2. tf-idf(TfidfTransformer): 빈도수에 따라 가중치 낮춤 -> 단어의 적합성 평가
3. 데이터 정제: 정규식 제거, 토큰화 (포터 어간 추출기), 불용어 제거

# 문서 분류 로지스틱 회귀 모델 훈련
1. train test분류
2. k겹 교차 검증 : 최적의 매개변수 조합 찾음
3. 최적의 매개변수를 이용해 학습, 분류 정확도 출력

# 대용량 데이터 처리 (미니배치)
1. 전처리(데이터load, 정제, 불용어 제거, 토큰화, 한문장씩 반환)
2. 미니 배치 함수 선언-> size만큼 문서 반환
3. hashing vectorizer
4. 모델 load(로지스틱 회귀 모델)
5. 외부 메모리 학습
6. 성능 확인

# 토픽 모델링(비지도)
### LDA기법
1. 데이터 load
2. CountVectorizer =BoW행렬 생성 + 전처리
3. LatentDirichletAllocation 사이킷 런의 LDA 학습
4. 중요도에 따라 오름차순 정렬 되어 있음
